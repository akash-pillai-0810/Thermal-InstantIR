## ComfyUI-Manager: installing dependencies done.
[2025-05-02 17:00:25.688] ** ComfyUI startup time: 2025-05-02 17:00:25.688
[2025-05-02 17:00:25.688] ** Platform: Darwin
[2025-05-02 17:00:25.688] ** Python version: 3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 10:07:17) [Clang 14.0.6 ]
[2025-05-02 17:00:25.688] ** Python executable: /opt/anaconda3/bin/python
[2025-05-02 17:00:25.688] ** ComfyUI Path: /Users/akashpillai/AI/ComfyUI
[2025-05-02 17:00:25.688] ** ComfyUI Base Folder Path: /Users/akashpillai/AI/ComfyUI
[2025-05-02 17:00:25.688] ** User directory: /Users/akashpillai/AI/ComfyUI/user
[2025-05-02 17:00:25.688] ** ComfyUI-Manager config path: /Users/akashpillai/AI/ComfyUI/user/default/ComfyUI-Manager/config.ini
[2025-05-02 17:00:25.688] ** Log path: /Users/akashpillai/AI/ComfyUI/user/comfyui.log

Prestartup times for custom nodes:
[2025-05-02 17:00:26.351]    1.4 seconds: /Users/akashpillai/AI/ComfyUI/custom_nodes/ComfyUI-Manager
[2025-05-02 17:00:26.351] 
[2025-05-02 17:00:27.139] Checkpoint files will always be loaded safely.
[2025-05-02 17:00:27.167] Total VRAM 16384 MB, total RAM 16384 MB
[2025-05-02 17:00:27.167] pytorch version: 2.7.0
[2025-05-02 17:00:27.168] Mac Version (15, 4, 1)
[2025-05-02 17:00:27.168] Set vram state to: DISABLED
[2025-05-02 17:00:27.168] Device: cpu
[2025-05-02 17:00:28.025] Using sub quadratic optimization for attention, if you have memory or speed issues try using: --use-split-cross-attention
[2025-05-02 17:00:28.969] Python version: 3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 10:07:17) [Clang 14.0.6 ]
[2025-05-02 17:00:28.969] ComfyUI version: 0.3.30
[2025-05-02 17:00:28.971] ComfyUI frontend version: 1.18.6
[2025-05-02 17:00:28.971] [Prompt Server] web root: /opt/anaconda3/lib/python3.12/site-packages/comfyui_frontend_package/static
[2025-05-02 17:00:29.408] ### Loading: ComfyUI-Manager (V3.31.13)
[2025-05-02 17:00:29.409] [ComfyUI-Manager] network_mode: public
[2025-05-02 17:00:29.487] ### ComfyUI Version: v0.3.30-37-g065d855f | Released on '2025-05-02'
[2025-05-02 17:00:29.633] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json
[2025-05-02 17:00:29.633] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json
[2025-05-02 17:00:30.965] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json
[2025-05-02 17:00:30.974] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json
[2025-05-02 17:00:30.996] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json
[2025-05-02 17:00:32.722] NumExpr defaulting to 8 threads.
[2025-05-02 17:00:33.502] FETCH ComfyRegistry Data: 5/83
[2025-05-02 17:00:33.757] 
Import times for custom nodes:
[2025-05-02 17:00:33.757]    0.0 seconds: /Users/akashpillai/AI/ComfyUI/custom_nodes/websocket_image_save.py
[2025-05-02 17:00:33.757]    0.1 seconds: /Users/akashpillai/AI/ComfyUI/custom_nodes/ComfyUI-Manager
[2025-05-02 17:00:33.757]    4.3 seconds: /Users/akashpillai/AI/ComfyUI/custom_nodes/ComfyUI_InstantIR_Wrapper
[2025-05-02 17:00:33.757] 
[2025-05-02 17:00:33.760] Starting server

[2025-05-02 17:00:33.761] To see the GUI go to: http://127.0.0.1:8188
[2025-05-02 17:00:36.467] FETCH ComfyRegistry Data: 10/83
[2025-05-02 17:00:39.402] FETCH ComfyRegistry Data: 15/83
[2025-05-02 17:00:42.321] FETCH ComfyRegistry Data: 20/83
[2025-05-02 17:00:45.292] FETCH ComfyRegistry Data: 25/83
[2025-05-02 17:00:48.258] FETCH ComfyRegistry Data: 30/83
[2025-05-02 17:00:51.189] FETCH ComfyRegistry Data: 35/83
[2025-05-02 17:00:51.491] got prompt
[2025-05-02 17:00:52.169] Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 15.58it/s]
[2025-05-02 17:00:54.154] FETCH ComfyRegistry Data: 40/83
[2025-05-02 17:00:57.103] FETCH ComfyRegistry Data: 45/83
[2025-05-02 17:01:00.037] FETCH ComfyRegistry Data: 50/83
[2025-05-02 17:01:00.503] Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
[2025-05-02 17:01:02.977] FETCH ComfyRegistry Data: 55/83
[2025-05-02 17:01:06.254] FETCH ComfyRegistry Data: 60/83
[2025-05-02 17:01:09.213] FETCH ComfyRegistry Data: 65/83
[2025-05-02 17:01:11.370] use lora alpha 1
[2025-05-02 17:01:11.596] /opt/anaconda3/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!
  warnings.warn(
[2025-05-02 17:01:12.804] use lcm lora alpha 8.0
[2025-05-02 17:01:12.807] Loading checkpoint...
[2025-05-02 17:01:13.045] FETCH ComfyRegistry Data: 70/83
[2025-05-02 17:01:16.224] FETCH ComfyRegistry Data: 75/83
[2025-05-02 17:01:19.159] FETCH ComfyRegistry Data: 80/83
[2025-05-02 17:01:22.158] FETCH ComfyRegistry Data [DONE]
[2025-05-02 17:01:22.214] [ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes
[2025-05-02 17:01:22.225] FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]
[2025-05-02 17:01:22.320] [ComfyUI-Manager] All startup tasks have been completed.
[2025-05-02 17:01:25.078] loading checkpoint done.
[2025-05-02 17:02:03.048] Start infer 1 images.
[2025-05-02 17:02:03.076] The config attributes {'interpolation_type': 'linear', 'skip_prk_steps': True, 'use_karras_sigmas': False} were passed to LCMSingleStepScheduler, but are not expected and will be ignored. Please verify your scheduler_config.json configuration file.
[2025-05-02 17:02:03.184] creative_restoration using previewer lora
[2025-05-02 17:02:03.229] /opt/anaconda3/lib/python3.12/site-packages/torch/cuda/memory.py:489: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
[2025-05-02 17:02:03.399] !!! Exception during processing !!! module 'torch._C' has no attribute '_cuda_resetPeakMemoryStats'
[2025-05-02 17:02:03.514] Traceback (most recent call last):
  File "/Users/akashpillai/AI/ComfyUI/execution.py", line 347, in execute
    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/akashpillai/AI/ComfyUI/execution.py", line 222, in get_output_data
    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/akashpillai/AI/ComfyUI/execution.py", line 194, in _map_node_over_list
    process_inputs(input_dict, i)
  File "/Users/akashpillai/AI/ComfyUI/execution.py", line 183, in process_inputs
    results.append(getattr(obj, func)(**inputs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/akashpillai/AI/ComfyUI/custom_nodes/ComfyUI_InstantIR_Wrapper/InstantIR_node.py", line 143, in main
    ouput_img = instantIR_main(image_list, model, seed, creative_restoration, steps, prompt, negative_prompt, cfg,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/akashpillai/AI/ComfyUI/custom_nodes/ComfyUI_InstantIR_Wrapper/utils.py", line 187, in instantIR_main
    torch.cuda.reset_max_memory_allocated(gpu)
  File "/opt/anaconda3/lib/python3.12/site-packages/torch/cuda/memory.py", line 494, in reset_max_memory_allocated
    return reset_peak_memory_stats(device=device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/torch/cuda/memory.py", line 374, in reset_peak_memory_stats
    return torch._C._cuda_resetPeakMemoryStats(device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'torch._C' has no attribute '_cuda_resetPeakMemoryStats'

[2025-05-02 17:02:03.522] Prompt executed in 72.03 seconds
[2025-05-02 18:41:35.547] 
Stopped server
